"""
AI Ëá™Âä®ÂåñÊµãËØïÂπ≥Âè∞ - ÂêéÁ´ØÊúçÂä°ÂÖ•Âè£

ÊîØÊåÅÁî®Êà∑Ëá™ÂÆö‰πâÂ§ßÊ®°ÂûãÊâßË°åÈ°πÁõÆÊµãËØï

‰ΩúËÄÖ: Ai_Test_Agent Team
"""
import os
import sys
import asyncio
import uvicorn
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from dotenv import load_dotenv

# Ê∑ªÂä†ÂΩìÂâçÁõÆÂΩïÂà∞Ë∑ØÂæÑ
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Windows ‰∫ã‰ª∂Âæ™ÁéØ‰øÆÂ§ç
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# Âä†ËΩΩÁéØÂ¢ÉÂèòÈáè
load_dotenv(os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env'))

# ÂØºÂÖ•Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñ
from database.connection import init_db

# ÂØºÂÖ•Ë∑ØÁî±
from Build_Use_case.router import router as test_cases_router
from Execute_test.router import router as execute_router
from Build_Report.router import router as report_router
from Bug_Analysis.router import router as bug_router
from Model_manage.router import router as model_router
from Email_manage.router import router as email_router
from Contact_manage.router import router as contact_router
from Dashboard.router import router as dashboard_router
from Api_Spec.router import router as spec_router
from Api_Test.router import router as api_test_router
from OneClick_Test.router import router as oneclick_router
from Security_Test.router import router as security_router


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Â∫îÁî®ÁîüÂëΩÂë®ÊúüÁÆ°ÁêÜ"""
    loop = asyncio.get_running_loop()
    print(f"\n[Debug] ÂΩìÂâç‰∫ã‰ª∂Âæ™ÁéØ: {type(loop)}")
    
    if sys.platform == 'win32' and not isinstance(loop, asyncio.ProactorEventLoop):
        print("[Warning] Windows Êú™‰ΩøÁî® ProactorEventLoop!")
    
    print("\n" + "=" * 80)
    print("üóÑÔ∏è  ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ì...")
    init_db()
    
    print("\n" + "=" * 80)
    print("ü§ñ LLM Ê®°ÂûãÈÖçÁΩÆÊ£ÄÊü•")
    print("=" * 80)

    try:
        from llm import get_active_llm_config
        config = get_active_llm_config()
        print(f"  ‚úì ‰ΩøÁî®Êï∞ÊçÆÂ∫ìÊ®°ÂûãÈÖçÁΩÆ")
        print(f"  ‚úì ÂΩìÂâçÊøÄÊ¥ªÊ®°Âûã: {config['model_name']}")
        print(f"  ‚úì ‰æõÂ∫îÂïÜ: {config.get('provider', 'N/A')}")
        print(f"  ‚úì Base URL: {config.get('base_url', 'N/A')}")
    except Exception as e:
        print(f"  ‚ö†Ô∏è Êó†Ê≥ïËé∑ÂèñÊï∞ÊçÆÂ∫ìÊ®°ÂûãÈÖçÁΩÆ: {e}")
        print(f"  ‚ö†Ô∏è ËØ∑Âú®Ê®°ÂûãÁÆ°ÁêÜÈ°µÈù¢Ê∑ªÂä†Âπ∂ÊøÄÊ¥ªÊ®°Âûã")
    
    print("\n" + "=" * 80)
    print("üìö API ÊñáÊ°£ËÆøÈóÆÂú∞ÂùÄÔºö")
    print("=" * 80)
    print(f"  ‚úì Swagger UI ÊñáÊ°£: http://localhost:8001/docs")
    print(f"  ‚úì ReDoc ÊñáÊ°£:       http://localhost:8001/redoc")
    print(f"  ‚úì OpenAPI JSON:    http://localhost:8001/openapi.json")
    print("=" * 80)
    
    print("\nüí° ÊèêÁ§∫Ôºö")
    print("  - Á≥ªÁªüÊîØÊåÅÂ§öÁßçÂ§ßÊ®°ÂûãÔºàOpenAI„ÄÅDeepSeek„ÄÅClaude Á≠âÔºâ")
    print("  - ÈÄöËøáÊ®°ÂûãÁÆ°ÁêÜÈ°µÈù¢ÈÖçÁΩÆÂíåÂàáÊç¢Ê®°Âûã")
    print("  - ‰ΩøÁî® browser-use ÊâßË°åËá™Âä®ÂåñÊµãËØï")
    print("=" * 80)
    
    print("\nüöÄ AI Ëá™Âä®ÂåñÊµãËØïÂπ≥Âè∞ API Â∑≤ÊàêÂäüÂêØÂä®ÔºÅ")
    print("=" * 80 + "\n")
    
    yield
    
    print("\nÊúçÂä°Â∑≤ÂÆâÂÖ®ÂÖ≥Èó≠\n")


# ÂàõÂª∫ FastAPI Â∫îÁî®
app = FastAPI(
    title="AI Test Agent API",
    description="""
    AI Ëá™Âä®ÂåñÊµãËØïÂπ≥Âè∞ API
    
    ## ÂäüËÉΩÁâπÊÄß
    
    - ü§ñ **Êô∫ËÉΩÊµãËØïÁî®‰æãÁîüÊàê** - Âü∫‰∫éÈúÄÊ±ÇËá™Âä®ÁîüÊàêÊµãËØïÁî®‰æã
    - üåê **Browser-Use Ëá™Âä®ÂåñÊâßË°å** - ‰ΩøÁî® AI Agent ÊâßË°åÊµèËßàÂô®ÊµãËØï
    - üìä **ÊµãËØïÊä•ÂëäÁîüÊàê** - Ëá™Âä®ÁîüÊàêËØ¶ÁªÜÁöÑÊµãËØïÊä•Âëä
    - üêõ **Bug Êô∫ËÉΩÂàÜÊûê** - Ëá™Âä®ÂàÜÊûêÊµãËØïÂ§±Ë¥•ÂéüÂõ†
    - üîß **Â§öÊ®°ÂûãÊîØÊåÅ** - ÊîØÊåÅ OpenAI„ÄÅDeepSeek„ÄÅClaude Á≠âÂ§öÁßçÂ§ßÊ®°Âûã
    
    ## ‰ΩøÁî®ÊµÅÁ®ã
    
    1. Âú®Ê®°ÂûãÁÆ°ÁêÜ‰∏≠ÈÖçÁΩÆÂπ∂ÊøÄÊ¥ª LLM Ê®°Âûã
    2. ÂàõÂª∫ÊàñÂØºÂÖ•ÊµãËØïÁî®‰æã
    3. ÊâßË°åÊµãËØïÔºàÂçïÊù°ÊàñÊâπÈáèÔºâ
    4. Êü•ÁúãÊµãËØïÊä•ÂëäÂíå Bug ÂàÜÊûê
    """,
    version="2.0.0",
    docs_url="/docs",
    redoc_url=None,
    openapi_url="/openapi.json",
    lifespan=lifespan
)

# CORS ÈÖçÁΩÆ
cors_origins = os.getenv('CORS_ORIGINS', 'http://localhost:5175').split(',')
app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ê≥®ÂÜåË∑ØÁî±
app.include_router(test_cases_router)
app.include_router(execute_router)
app.include_router(report_router)
app.include_router(bug_router)
app.include_router(model_router)
app.include_router(email_router)
app.include_router(contact_router)
app.include_router(dashboard_router)
app.include_router(spec_router)
app.include_router(api_test_router)
app.include_router(oneclick_router)
app.include_router(security_router)


# Ëá™ÂÆö‰πâ ReDoc Á´ØÁÇπ
@app.get("/redoc", include_in_schema=False)
async def redoc_html() -> HTMLResponse:
    """ReDoc API ÊñáÊ°£È°µÈù¢"""
    return HTMLResponse(
        content="""
        <!DOCTYPE html>
        <html>
            <head>
                <title>AI Test Agent - API ÊñáÊ°£</title>
                <meta charset="utf-8"/>
                <meta name="viewport" content="width=device-width, initial-scale=1">
                <link href="https://fonts.googleapis.com/css?family=Montserrat:300,400,700|Roboto:300,400,700" rel="stylesheet">
                <style>
                    body {
                        margin: 0;
                        padding: 0;
                    }
                </style>
            </head>
            <body>
                <redoc spec-url="/openapi.json"></redoc>
                <script src="https://cdn.jsdelivr.net/npm/redoc@latest/bundles/redoc.standalone.js"></script>
            </body>
        </html>
        """
    )


@app.get("/")
async def root():
    """API Ê†πÁ´ØÁÇπ"""
    return {
        "message": "AI Test Agent API is running",
        "version": "2.0.0",
        "docs": "/docs",
        "features": [
            "Multi-LLM support (OpenAI, DeepSeek, Claude, etc.)",
            "Intelligent test case generation",
            "Browser-Use automated testing",
            "AI-powered bug analysis"
        ]
    }


@app.get("/health")
async def health_check():
    """ÂÅ•Â∫∑Ê£ÄÊü•Á´ØÁÇπ"""
    try:
        from llm import get_active_llm_config
        config = get_active_llm_config()
        llm_status = "active"
        llm_model = config.get('model_name', 'unknown')
    except Exception:
        llm_status = "not_configured"
        llm_model = None
    
    return {
        "status": "healthy",
        "service": "AI Test Agent",
        "version": "2.0.0",
        "llm": {
            "status": llm_status,
            "model": llm_model
        }
    }


if __name__ == "__main__":
    # Windows È¢ùÂ§ñÂ§ÑÁêÜ
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    host = os.getenv('HOST', '0.0.0.0')
    port = int(os.getenv('PORT', 8001))
    debug = os.getenv('DEBUG', 'True').lower() == 'true'
    
    uvicorn.run(
        "app:app",
        host=host,
        port=port,
        reload=False
    )
