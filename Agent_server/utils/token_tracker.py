"""
Token è·Ÿè¸ªæœåŠ¡ - å€Ÿé‰´ browser-use çš„ token ç»Ÿè®¡å®ç°

åŠŸèƒ½:
- å®æ—¶è·Ÿè¸ªæ¯æ¬¡ LLM è°ƒç”¨çš„ token ä½¿ç”¨
- æ”¯æŒç¼“å­˜ token ç»Ÿè®¡ï¼ˆprompt_cached_tokens, cache_creation_tokensï¼‰
- è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„æ€»ä½¿ç”¨é‡å’Œæˆæœ¬
- æŒ‰æ¨¡å‹åˆ†ç±»ç»Ÿè®¡
- æŒä¹…åŒ–åˆ°æ•°æ®åº“

ä½œè€…: Ai_Test_Agent Team
ç‰ˆæœ¬: 2.0 (åŸºäº browser-use 0.11.1)
"""

import logging
from datetime import datetime
from typing import Dict, List, Optional
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


# ==================== æ•°æ®æ¨¡å‹ ====================

class TokenUsage(BaseModel):
    """å•æ¬¡ LLM è°ƒç”¨çš„ token ä½¿ç”¨æƒ…å†µ"""
    prompt_tokens: int = 0
    completion_tokens: int = 0
    
    # ç¼“å­˜ç›¸å…³ tokenï¼ˆAnthropic Claude ç­‰æ¨¡å‹æ”¯æŒï¼‰
    prompt_cached_tokens: Optional[int] = None  # ä»ç¼“å­˜è¯»å–çš„ token
    prompt_cache_creation_tokens: Optional[int] = None  # åˆ›å»ºç¼“å­˜çš„ token
    
    @property
    def total_tokens(self) -> int:
        """æ€» token æ•°é‡"""
        return self.prompt_tokens + self.completion_tokens


class TokenUsageEntry(BaseModel):
    """token ä½¿ç”¨è®°å½•æ¡ç›®"""
    model_name: str
    timestamp: datetime
    usage: TokenUsage
    step_number: Optional[int] = None  # æµ‹è¯•æ­¥éª¤ç¼–å·
    action_type: Optional[str] = None  # åŠ¨ä½œç±»å‹


class ModelUsageStats(BaseModel):
    """æŒ‰æ¨¡å‹ç»Ÿè®¡çš„ä½¿ç”¨æƒ…å†µ"""
    model_name: str
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    cached_tokens: int = 0  # æ€»ç¼“å­˜ token
    cache_creation_tokens: int = 0  # ç¼“å­˜åˆ›å»º token
    invocations: int = 0  # è°ƒç”¨æ¬¡æ•°
    
    @property
    def average_tokens_per_call(self) -> float:
        """æ¯æ¬¡è°ƒç”¨å¹³å‡ token æ•°"""
        return self.total_tokens / self.invocations if self.invocations > 0 else 0.0
    
    @property
    def cache_hit_rate(self) -> float:
        """ç¼“å­˜å‘½ä¸­ç‡"""
        total_prompt = self.prompt_tokens + self.cache_creation_tokens
        if total_prompt == 0:
            return 0.0
        return self.cached_tokens / total_prompt


class UsageSummary(BaseModel):
    """ä½¿ç”¨æƒ…å†µæ±‡æ€»"""
    total_prompt_tokens: int = 0
    total_completion_tokens: int = 0
    total_tokens: int = 0
    total_cached_tokens: int = 0
    total_cache_creation_tokens: int = 0
    total_invocations: int = 0
    
    by_model: Dict[str, ModelUsageStats] = Field(default_factory=dict)
    
    @property
    def cache_hit_rate(self) -> float:
        """ç¼“å­˜å‘½ä¸­ç‡ (0.0 - 1.0)"""
        total_prompt = self.total_prompt_tokens + self.total_cache_creation_tokens
        if total_prompt == 0:
            return 0.0
        return self.total_cached_tokens / total_prompt


# ==================== Token è·Ÿè¸ªå™¨ ====================

class TokenTracker:
    """Token ä½¿ç”¨è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.usage_history: List[TokenUsageEntry] = []
        self._current_step: Optional[int] = None
    
    def set_current_step(self, step_number: int):
        """è®¾ç½®å½“å‰æ­¥éª¤ç¼–å·"""
        self._current_step = step_number
    
    def add_usage(
        self,
        model_name: str,
        prompt_tokens: int,
        completion_tokens: int,
        prompt_cached_tokens: Optional[int] = None,
        prompt_cache_creation_tokens: Optional[int] = None,
        action_type: Optional[str] = None
    ) -> TokenUsageEntry:
        """
        æ·»åŠ ä¸€æ¬¡ token ä½¿ç”¨è®°å½•
        
        Args:
            model_name: æ¨¡å‹åç§°
            prompt_tokens: è¾“å…¥ token æ•°
            completion_tokens: è¾“å‡º token æ•°
            prompt_cached_tokens: ä»ç¼“å­˜è¯»å–çš„ token æ•°
            prompt_cache_creation_tokens: åˆ›å»ºç¼“å­˜çš„ token æ•°
            action_type: åŠ¨ä½œç±»å‹
        
        Returns:
            TokenUsageEntry: ä½¿ç”¨è®°å½•
        """
        usage = TokenUsage(
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=prompt_tokens + completion_tokens,
            prompt_cached_tokens=prompt_cached_tokens,
            prompt_cache_creation_tokens=prompt_cache_creation_tokens
        )
        
        entry = TokenUsageEntry(
            model_name=model_name,
            timestamp=datetime.now(),
            usage=usage,
            step_number=self._current_step,
            action_type=action_type
        )
        
        self.usage_history.append(entry)
        
        # æ—¥å¿—è¾“å‡º
        self._log_usage(entry)
        
        return entry
    
    def _log_usage(self, entry: TokenUsageEntry):
        """è®°å½• token ä½¿ç”¨æ—¥å¿—ï¼ˆå¸¦é¢œè‰²è¾“å‡ºï¼‰"""
        usage = entry.usage
        
        # è®¡ç®—æ–° tokenï¼ˆéç¼“å­˜ï¼‰
        new_prompt_tokens = usage.prompt_tokens - (usage.prompt_cached_tokens or 0)
        
        parts = []
        
        # è¾“å…¥ token
        if usage.prompt_cached_tokens or usage.prompt_cache_creation_tokens:
            if new_prompt_tokens > 0:
                parts.append(f"ğŸ†• {new_prompt_tokens}")
            if usage.prompt_cached_tokens:
                parts.append(f"ğŸ’¾ {usage.prompt_cached_tokens}")
            if usage.prompt_cache_creation_tokens:
                parts.append(f"ğŸ“ {usage.prompt_cache_creation_tokens}")
        else:
            parts.append(f"ğŸ“¥ {usage.prompt_tokens}")
        
        # è¾“å‡º token
        parts.append(f"ğŸ“¤ {usage.completion_tokens}")
        
        # æ€»è®¡
        parts.append(f"Î£ {usage.total_tokens}")
        
        step_info = f"[Step {entry.step_number}]" if entry.step_number else ""
        action_info = f"[{entry.action_type}]" if entry.action_type else ""
        
        logger.info(f"[TokenTracker] {step_info}{action_info} {entry.model_name}: {' | '.join(parts)}")
    
    def get_summary(self) -> UsageSummary:
        """
        è·å–ä½¿ç”¨æƒ…å†µæ±‡æ€»
        
        Returns:
            UsageSummary: æ±‡æ€»ç»Ÿè®¡
        """
        summary = UsageSummary()
        
        for entry in self.usage_history:
            usage = entry.usage
            model_name = entry.model_name
            
            # æ›´æ–°æ€»è®¡
            summary.total_prompt_tokens += usage.prompt_tokens
            summary.total_completion_tokens += usage.completion_tokens
            summary.total_tokens += usage.total_tokens
            summary.total_cached_tokens += usage.prompt_cached_tokens or 0
            summary.total_cache_creation_tokens += usage.prompt_cache_creation_tokens or 0
            summary.total_invocations += 1
            
            # æŒ‰æ¨¡å‹ç»Ÿè®¡
            if model_name not in summary.by_model:
                summary.by_model[model_name] = ModelUsageStats(model_name=model_name)
            
            model_stats = summary.by_model[model_name]
            model_stats.prompt_tokens += usage.prompt_tokens
            model_stats.completion_tokens += usage.completion_tokens
            model_stats.total_tokens += usage.total_tokens
            model_stats.cached_tokens += usage.prompt_cached_tokens or 0
            model_stats.cache_creation_tokens += usage.prompt_cache_creation_tokens or 0
            model_stats.invocations += 1
        
        return summary
    
    def clear(self):
        """æ¸…ç©ºä½¿ç”¨å†å²"""
        self.usage_history.clear()
        self._current_step = None
    
    def get_model_usage(self, model_name: str) -> Optional[ModelUsageStats]:
        """
        è·å–æŒ‡å®šæ¨¡å‹çš„ä½¿ç”¨ç»Ÿè®¡
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            ModelUsageStats: æ¨¡å‹ç»Ÿè®¡ï¼Œå¦‚æœæ²¡æœ‰è®°å½•åˆ™è¿”å› None
        """
        summary = self.get_summary()
        return summary.by_model.get(model_name)


# ==================== æ•°æ®åº“æŒä¹…åŒ–æœåŠ¡ ====================

class TokenStatisticsService:
    """Token ç»Ÿè®¡æ•°æ®åº“æœåŠ¡"""
    
    @staticmethod
    def update_active_model_token_usage(
        db: Session,
        token_usage: Dict[str, int]
    ) -> Dict[str, any]:
        """
        æ›´æ–°æ¿€æ´»æ¨¡å‹çš„ token ä½¿ç”¨é‡
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            token_usage: token ä½¿ç”¨å­—å…¸ {'prompt_tokens': xxx, 'completion_tokens': xxx, 'total_tokens': xxx}
        
        Returns:
            æ›´æ–°ç»“æœ
        """
        try:
            from database.connection import LLMModel
            
            # è·å–æ¿€æ´»çš„æ¨¡å‹
            active_model = db.query(LLMModel).filter(
                LLMModel.is_active == True
            ).first()
            
            if not active_model:
                return {"success": False, "message": "æœªæ‰¾åˆ°æ¿€æ´»çš„æ¨¡å‹"}
            
            total_tokens = token_usage.get('total_tokens', 0)
            
            # æ›´æ–°æ¨¡å‹çš„ä»Šæ—¥ä½¿ç”¨é‡
            active_model.tokens_used_today = (active_model.tokens_used_today or 0) + total_tokens
            active_model.updated_at = datetime.now()
            
            db.commit()
            
            logger.info(
                f"[TokenStats] æ›´æ–°æ¨¡å‹ token ä½¿ç”¨: "
                f"model={active_model.model_name}, "
                f"prompt={token_usage.get('prompt_tokens', 0)}, "
                f"completion={token_usage.get('completion_tokens', 0)}, "
                f"total={total_tokens}, "
                f"today_total={active_model.tokens_used_today}"
            )
            
            return {
                "success": True,
                "data": {
                    "model_id": active_model.id,
                    "model_name": active_model.model_name,
                    "tokens_added": total_tokens,
                    "tokens_used_today": active_model.tokens_used_today
                }
            }
            
        except Exception as e:
            logger.error(f"[TokenStats] æ›´æ–° token ä½¿ç”¨å¤±è´¥: {e}")
            db.rollback()
            return {"success": False, "message": str(e)}
    
    @staticmethod
    def reset_daily_usage(db: Session) -> Dict[str, any]:
        """
        é‡ç½®æ‰€æœ‰æ¨¡å‹çš„ä»Šæ—¥ä½¿ç”¨é‡ï¼ˆæ¯æ—¥å‡Œæ™¨è°ƒç”¨ï¼‰
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
        
        Returns:
            é‡ç½®ç»“æœ
        """
        try:
            from database.connection import LLMModel
            
            models = db.query(LLMModel).all()
            reset_count = 0
            
            for model in models:
                if model.tokens_used_today and model.tokens_used_today > 0:
                    model.tokens_used_today = 0
                    reset_count += 1
            
            db.commit()
            
            logger.info(f"[TokenStats] å·²é‡ç½® {reset_count} ä¸ªæ¨¡å‹çš„ä»Šæ—¥ token ä½¿ç”¨é‡")
            
            return {
                "success": True,
                "message": f"å·²é‡ç½® {reset_count} ä¸ªæ¨¡å‹çš„ä»Šæ—¥ä½¿ç”¨é‡"
            }
            
        except Exception as e:
            logger.error(f"[TokenStats] é‡ç½®ä»Šæ—¥ä½¿ç”¨é‡å¤±è´¥: {e}")
            db.rollback()
            return {"success": False, "message": str(e)}
    
    @staticmethod
    def get_today_usage(db: Session, model_id: Optional[int] = None) -> Dict[str, any]:
        """
        è·å–ä»Šæ—¥ token ä½¿ç”¨é‡
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            model_id: å¯é€‰ï¼ŒæŒ‡å®šæ¨¡å‹ ID
        
        Returns:
            ä»Šæ—¥ä½¿ç”¨é‡ç»Ÿè®¡
        """
        try:
            from database.connection import LLMModel
            
            query = db.query(LLMModel)
            
            if model_id:
                query = query.filter(LLMModel.id == model_id)
            
            models = query.all()
            
            total_usage = 0
            model_usage = []
            
            for model in models:
                usage = model.tokens_used_today or 0
                total_usage += usage
                model_usage.append({
                    "model_id": model.id,
                    "model_name": model.model_name,
                    "tokens_used_today": usage
                })
            
            return {
                "success": True,
                "data": {
                    "total_tokens": total_usage,
                    "models": model_usage
                }
            }
            
        except Exception as e:
            logger.error(f"[TokenStats] è·å–ä»Šæ—¥ä½¿ç”¨é‡å¤±è´¥: {e}")
            return {"success": False, "message": str(e)}
